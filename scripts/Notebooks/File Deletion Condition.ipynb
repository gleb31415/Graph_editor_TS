{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ZIP → LaTeX Concise Notes (via OpenRouter)\n",
        "\n",
        "Этот ноутбук берёт ZIP-архивы **из текущей папки**, извлекает из каждого `main.tex`,\n",
        "отправляет его содержимое в OpenRouter и получает **краткий конспект**,\n",
        "который **сохраняет структуру и тэги**, но оставляет только пару базовых определений\n",
        "и формул **без пояснений**. Результаты сохраняются в **отдельную папку**.\n",
        "\n",
        "> ⚠️ **Безопасность ключа**: по умолчанию ноутбук берёт ключ из переменной окружения\n",
        "`OPENROUTER_API_KEY`. Можно также вставить ключ вручную в параметрах ниже (не рекомендуется).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==== Параметры ====\n",
        "# Папка, куда будут сохраняться итоговые .tex с конспектами (создастся при отсутствии)\n",
        "DEST_DIR = \"summaries\"\n",
        "\n",
        "# Максимальное количество ZIP-архивов для обработки (чтобы не сжигать бюджет)\n",
        "MAX_FILES = 100  # ← поменяйте по необходимости\n",
        "\n",
        "# Название файла внутри ZIP (если лежит не в корне, скрипт найдёт по имени)\n",
        "TARGET_TEX_BASENAME = \"main.tex\"\n",
        "\n",
        "# Выберите модель OpenRouter (актуальные ID смотрите на https://openrouter.ai/models)\n",
        "# Исправлено: корректный ID — с дефисом `qwen-2.5`, а не `qwen2.5`\n",
        "MODEL_ID = \"qwen/qwen-2.5-7b-instruct\"\n",
        "# Резервные модели, если основная недоступна/невалидна\n",
        "MODEL_FALLBACKS = [\n",
        "    \"qwen/qwen-2.5-3b-instruct\",\n",
        "    \"meta-llama/llama-3.1-8b-instruct\",\n",
        "    \"mistralai/mistral-small-latest\",\n",
        "    \"openai/gpt-4o-mini\",\n",
        "]\n",
        "\n",
        "# Источник API-ключа. По умолчанию читаем из переменной окружения.\n",
        "# Можно раскомментировать строку ниже и ВСТАВИТЬ ключ напрямую (менее безопасно).\n",
        "import os\n",
        "\n",
        "OPENROUTER_API_KEY = \"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\"  # ← ключ пользователя (не рекомендуется хранить в коде)\n",
        "# OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\", \"\")  # безопаснее брать из окружения\n",
        "\n",
        "# Дополнительно: мягкий DRY-RUN. Если True — НИЧЕГО НЕ ОТПРАВЛЯЕТСЯ в сеть,\n",
        "# а вместо запроса сохраняется заглушка (для проверки пайплайна).\n",
        "DRY_RUN = False\n",
        "\n",
        "# Ограничение на размер исходного LaTeX для отправки (символы).\n",
        "# Если файл больше — будет обрезан по хвосту с уведомлением.\n",
        "MAX_LATEX_CHARS = 120_000\n",
        "\n",
        "# Управление печатью исходного main.tex в консоль\n",
        "PRINT_LATEX_TO_CONSOLE = True\n",
        "LATEX_PREVIEW_CHARS = 200000  # сколько символов показывать в консоли"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найдено ZIP: 72\n",
            " • physics__7.avgspd.zip\n",
            " • physics__7.force.zip\n",
            " • physics__7arhimed.zip\n",
            " • physics__7friction.zip\n",
            " • physics__7graphs.zip\n",
            " • physics__7kinblok.zip\n",
            " • physics__7mgN.zip\n",
            " • physics__7pressure.zip\n",
            " • physics__7rpo.zip\n",
            " • physics__7springs.zip\n",
            " … и ещё 62\n"
          ]
        }
      ],
      "source": [
        "# ==== Поиск ZIP-архивов в текущей папке ====\n",
        "import glob\n",
        "zip_paths = sorted([p for p in glob.glob(\"*.zip\") if os.path.isfile(p)])\n",
        "print(f\"Найдено ZIP: {len(zip_paths)}\")\n",
        "for p in zip_paths[:10]:\n",
        "    print(\" •\", p)\n",
        "if len(zip_paths) > 10:\n",
        "    print(\" … и ещё\", len(zip_paths)-10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==== Подготовка промпта для модели ====\n",
        "# Система и инструкция сформулированы так, чтобы модель\n",
        "# возвращала краткий конспект с сохранением LaTeX-структуры.\n",
        "SYSTEM_MSG = (\n",
        "    \"You are a LaTeX condenser. Given a LaTeX file (main.tex), \"\n",
        "    \"produce a NEW LaTeX file that preserves the original structure, environments, and tags \"\n",
        "    \"as much as reasonably possible, but replaces the content with a very short concise outline. \"\n",
        "    \"The outline must contain only a few basic definitions and formulas, without explanations. \"\n",
        "    \"Do not add commentary. Output ONLY the LaTeX content.\"\n",
        ")\n",
        "\n",
        "USER_TEMPLATE = (\n",
        "    \"Here is the original LaTeX file main.tex between <latex> tags. \"\n",
        "    \"Create a concise version (keep structure and tags, keep it compilable). \"\n",
        "    \"Only a couple of core definitions and formulas, no explanations.\\n\\n\"\n",
        "    \"<latex>\\n{latex}\\n</latex>\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Ключ найден (из параметров).\n",
            "\n",
            "————————————————————————————————————————————————————————————\n",
            "ZIP: physics__7.avgspd.zip\n",
            "  → Модель: openai/gpt-4.1-mini\n",
            "  ✅ Сохранено: summaries/physics__7.avgspd__summary.tex\n",
            "\n",
            "————————————————————————————————————————————————————————————\n",
            "ZIP: physics__7.force.zip\n",
            "  → Модель: openai/gpt-4.1-mini\n",
            "  ✅ Сохранено: summaries/physics__7.avgspd__summary.tex\n",
            "\n",
            "————————————————————————————————————————————————————————————\n",
            "ZIP: physics__7.force.zip\n",
            "  → Модель: openai/gpt-4.1-mini\n",
            "  ✅ Сохранено: summaries/physics__7.force__summary.tex\n",
            "Достигнут лимит MAX_FILES=2. Останавливаюсь.\n",
            "\n",
            "Итог: обработано 2 архив(ов).\n",
            "Лог: summaries/run_log.csv\n",
            "  ✅ Сохранено: summaries/physics__7.force__summary.tex\n",
            "Достигнут лимит MAX_FILES=2. Останавливаюсь.\n",
            "\n",
            "Итог: обработано 2 архив(ов).\n",
            "Лог: summaries/run_log.csv\n"
          ]
        }
      ],
      "source": [
        "# ==== Обработка ZIP → main.tex → OpenRouter → summary.tex ====\n",
        "import zipfile, requests, pathlib, csv, time, datetime, os\n",
        "\n",
        "os.makedirs(DEST_DIR, exist_ok=True)\n",
        "log_rows = []\n",
        "ts = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "# Обновленный системный промпт\n",
        "SYSTEM_MSG = (\n",
        "    \"You are a strict LaTeX summarizer. \"\n",
        "    \"Given a LaTeX file, output a NEW LaTeX document that preserves the same structure \"\n",
        "    \"(documentclass, usepackage, sectioning, environments, math blocks). \"\n",
        "    \"Keep exactly 1-2 of the most central formulas, and only a few short keywords or topic names \"\n",
        "    \"to hint what the text is about. \"\n",
        "    \"Do NOT include explanations, derivations, or comments. \"\n",
        "    \"Do NOT remove LaTeX tags — your output must remain fully compilable.\"\n",
        ")\n",
        "\n",
        "def call_openrouter(api_key: str, model: str, system: str, user_content: str) -> str:\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"HTTP-Referer\": \"http://localhost\",\n",
        "        \"X-Title\": \"Zip-Tex-Condenser-Notebook\",\n",
        "    }\n",
        "    body = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": user_content},\n",
        "        ],\n",
        "        \"temperature\": 0.0,  # минимизируем \"творчество\"\n",
        "    }\n",
        "    resp = session.post(url, headers=headers, json=body, timeout=120)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "def call_openrouter_with_fallbacks(api_key: str, models: list[str], system: str, user_content: str) -> str:\n",
        "    last_err_txt = None\n",
        "    for mid in models:\n",
        "        try:\n",
        "            print(f\"  → Модель: {mid}\")\n",
        "            return call_openrouter(api_key, mid, system, user_content)\n",
        "        except requests.HTTPError as e:\n",
        "            err_text = getattr(e.response, 'text', '')[:200]\n",
        "            print(f\"    ↩︎ HTTP ошибка {mid}: {e} — {err_text}\")\n",
        "            last_err_txt = err_text\n",
        "            time.sleep(0.5)\n",
        "        except Exception as e:\n",
        "            print(f\"    ↩︎ Ошибка модели {mid}: {e}\")\n",
        "            last_err_txt = str(e)\n",
        "            time.sleep(0.5)\n",
        "    raise RuntimeError(f\"Все модели не сработали. Последняя ошибка: {last_err_txt}\")\n",
        "\n",
        "def read_main_tex_from_zip(zip_path: str, basename: str = TARGET_TEX_BASENAME) -> str | None:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "        names = zf.namelist()\n",
        "        candidates = [n for n in names if n.endswith(\"/\"+basename) or n == basename]\n",
        "        if not candidates:\n",
        "            candidates = [n for n in names if n.split(\"/\")[-1] == basename]\n",
        "        if not candidates:\n",
        "            return None\n",
        "        with zf.open(candidates[0], 'r') as f:\n",
        "            return f.read().decode(\"utf-8\", errors=\"replace\")\n",
        "\n",
        "if not OPENROUTER_API_KEY:\n",
        "    print(\"⚠️ OPENROUTER_API_KEY не найден. Установите переменную окружения или вставьте ключ в параметры.\")\n",
        "else:\n",
        "    print(\"✅ Ключ найден (из параметров).\")\n",
        "\n",
        "# Модели: сначала GPT-4.1 (или gpt-4o-mini), потом Qwen\n",
        "MODEL_PRIORITIES = [\n",
        "    \"openai/gpt-4.1-mini\",\n",
        "    \"qwen/qwen2.5-7b-instruct\",\n",
        "]\n",
        "\n",
        "processed = 0\n",
        "for zip_path in zip_paths:\n",
        "    if processed >= MAX_FILES:\n",
        "        print(f\"Достигнут лимит MAX_FILES={MAX_FILES}. Останавливаюсь.\")\n",
        "        break\n",
        "\n",
        "    print(\"\\n\" + \"—\"*60)\n",
        "    print(f\"ZIP: {zip_path}\")\n",
        "    raw = read_main_tex_from_zip(zip_path)\n",
        "    if raw is None:\n",
        "        print(\"  ✖ main.tex не найден — пропуск.\")\n",
        "        log_rows.append([ts, zip_path, \"\", \"main.tex not found\", \"0\", \"0\"])\n",
        "        continue\n",
        "\n",
        "    if len(raw) > MAX_LATEX_CHARS:\n",
        "        raw = raw[:MAX_LATEX_CHARS]\n",
        "\n",
        "    user_msg = USER_TEMPLATE.format(latex=raw)\n",
        "\n",
        "    try:\n",
        "        if DRY_RUN:\n",
        "            condensed = \"% DRY RUN — сжатый LaTeX будет здесь\\n\\\\documentclass{article}\\n\\\\begin{document}\\n...\\n\\\\end{document}\\n\"\n",
        "        else:\n",
        "            condensed = call_openrouter_with_fallbacks(\n",
        "                OPENROUTER_API_KEY,\n",
        "                MODEL_PRIORITIES,\n",
        "                SYSTEM_MSG,\n",
        "                user_msg,\n",
        "            )\n",
        "\n",
        "        base = pathlib.Path(zip_path).stem\n",
        "        out_name = f\"{base}__summary.tex\"\n",
        "        out_path = os.path.join(DEST_DIR, out_name)\n",
        "\n",
        "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(condensed)\n",
        "\n",
        "        print(f\"  ✅ Сохранено: {out_path}\")\n",
        "        log_rows.append([ts, zip_path, out_path, \"ok\", str(len(raw)), str(len(condensed))])\n",
        "        processed += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✖ Ошибка: {e}\")\n",
        "        log_rows.append([ts, zip_path, \"\", str(e), str(len(raw)), \"0\"])\n",
        "\n",
        "# Запись лога\n",
        "log_csv = os.path.join(DEST_DIR, \"run_log.csv\")\n",
        "with open(log_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"timestamp\", \"zip_path\", \"output_path\", \"status\", \"input_len\", \"output_len\"])\n",
        "    writer.writerows(log_rows)\n",
        "\n",
        "print(\"\\nИтог: обработано\", processed, \"архив(ов).\")\n",
        "print(\"Лог:\", log_csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Создано .tex файлов: 3\n",
            " • physics__7.avgspd__summary.tex\n",
            " • physics__7.force__summary.tex\n",
            " • physics__7arhimed__summary.tex\n"
          ]
        }
      ],
      "source": [
        "# ==== Просмотр результатов ====\n",
        "\n",
        "import pandas as pd, os\n",
        "\n",
        "log_csv = os.path.join(DEST_DIR, \"run_log.csv\")\n",
        "\n",
        "# Список созданных файлов .tex\n",
        "created = [p for p in os.listdir(DEST_DIR) if p.endswith(\".tex\")]\n",
        "print(\"Создано .tex файлов:\", len(created))\n",
        "for p in created[:10]:\n",
        "    print(\" •\", p)\n",
        "if len(created) > 10:\n",
        "    print(\" … и ещё\", len(created)-10)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
